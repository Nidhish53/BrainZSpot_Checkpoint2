{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alphabet Recognition System using Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Network (CNN) is a Deep Learning Algorithm widely used for character recognition. This algorithm identifies the alphabet from the given input image.\n",
    "\n",
    "The accuracy achieved using this algorithm is 93.42%.\n",
    "\n",
    "## 1. Anvil Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Authenticated OK\n"
     ]
    }
   ],
   "source": [
    "import anvil.server\n",
    "import anvil.media\n",
    "anvil.server.connect(\"44STZQZQTYAAVHHWGRPMXDRN-P5VUQGPD3HW5UMWJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyttsx3\n",
      "  Downloading pyttsx3-2.90-py3-none-any.whl (39 kB)\n",
      "Collecting pypiwin32\n",
      "  Downloading pypiwin32-223-py3-none-any.whl (1.7 kB)\n",
      "Requirement already satisfied: comtypes in c:\\users\\shree\\anaconda3\\lib\\site-packages (from pyttsx3) (1.1.10)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\shree\\anaconda3\\lib\\site-packages (from pyttsx3) (302)\n",
      "Installing collected packages: pypiwin32, pyttsx3\n",
      "Successfully installed pypiwin32-223 pyttsx3-2.90\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "#randomLetter = 'h'\n",
    "randomLetter = random.choice(string.ascii_letters)\n",
    "modified_string = randomLetter.translate({ord('h'): None, ord('q'): None})\n",
    "#print(randomLetter)\n",
    "\n",
    "import pyttsx3\n",
    "text_speech=pyttsx3.init()\n",
    "#ans=input()\n",
    "text_speech.say(\"Please write the letter\")\n",
    "text_speech.say(randomLetter)\n",
    "text_speech.runAndWait()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining the Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               147584    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 26)                3354      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,082\n",
      "Trainable params: 161,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (32,32,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dense(units = 26, activation = 'softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 501 images belonging to 26 classes.\n",
      "Found 261 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory = 'Training',\n",
    "    target_size = (32,32),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical'\n",
    "\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory = 'Testing',\n",
    "    target_size = (32,32),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shree\\AppData\\Local\\Temp\\ipykernel_11576\\2069286868.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - ETA: 0s - loss: 3.1301 - accuracy: 0.1457WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 16 batches). You may need to use the repeat() function when building your dataset.\n",
      "16/16 [==============================] - 3s 112ms/step - loss: 3.1301 - accuracy: 0.1457 - val_loss: 2.8933 - val_accuracy: 0.1839\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 2.1835 - accuracy: 0.4571\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 1.0424 - accuracy: 0.6866\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                         steps_per_epoch = 16,\n",
    "                         epochs = 3,\n",
    "                         validation_data = test_generator,\n",
    "                         validation_steps = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving/Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\conv2d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\max_pooling2d\n",
      "......vars\n",
      "...layers\\max_pooling2d_1\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-03-11 18:52:55         3090\n",
      "metadata.json                                  2023-03-11 18:52:55           64\n",
      "variables.h5                                   2023-03-11 18:52:55      1965088\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(model, open('CNN_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-03-11 18:52:54         3090\n",
      "metadata.json                                  2023-03-11 18:52:54           64\n",
      "variables.h5                                   2023-03-11 18:52:54      1965088\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\\conv2d\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\conv2d_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\flatten\n",
      "......vars\n",
      "...layers\\max_pooling2d\n",
      "......vars\n",
      "...layers\\max_pooling2d_1\n",
      "......vars\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('CNN_model.sav','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(result):\n",
    "    if result[0][0] == 1:\n",
    "        return('a')\n",
    "    elif result[0][1] == 1:\n",
    "        return ('b')\n",
    "    elif result[0][2] == 1:\n",
    "        return ('c')\n",
    "    elif result[0][3] == 1:\n",
    "        return ('d')\n",
    "    elif result[0][4] == 1:\n",
    "        return ('e')\n",
    "    elif result[0][5] == 1:\n",
    "        return ('f')\n",
    "    elif result[0][6] == 1:\n",
    "        return ('g')\n",
    "    elif result[0][7] == 1:\n",
    "        return ('h')\n",
    "    elif result[0][8] == 1:\n",
    "        return ('i')\n",
    "    elif result[0][9] == 1:\n",
    "        return ('j')\n",
    "    elif result[0][10] == 1:\n",
    "        return ('k')\n",
    "    elif result[0][11] == 1:\n",
    "        return ('l')\n",
    "    elif result[0][12] == 1:\n",
    "        return ('m')\n",
    "    elif result[0][13] == 1:\n",
    "        return ('n')\n",
    "    elif result[0][14] == 1:\n",
    "        return ('o')\n",
    "    elif result[0][15] == 1:\n",
    "        return ('p')\n",
    "    elif result[0][16] == 1:\n",
    "        return ('q')\n",
    "    elif result[0][17] == 1:\n",
    "        return ('r')\n",
    "    elif result[0][18] == 1:\n",
    "        return ('s')\n",
    "    elif result[0][19] == 1:\n",
    "        return ('t')\n",
    "    elif result[0][20] == 1:\n",
    "        return ('u')\n",
    "    elif result[0][21] == 1:\n",
    "        return ('v')\n",
    "    elif result[0][22] == 1:\n",
    "        return ('w')\n",
    "    elif result[0][23] == 1:\n",
    "        return ('x')\n",
    "    elif result[0][24] == 1:\n",
    "        return ('y')\n",
    "    elif result[0][25] == 1:\n",
    "        return ('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted Alphabet is: d\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename = r'Testing/'+randomLetter+'/24.png'\n",
    "test_image = tf.keras.utils.load_img(filename, target_size = (32,32))\n",
    "plt.imshow(test_image)\n",
    "test_image =  tf.keras.utils.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "\n",
    "result = model.predict(test_image)\n",
    "result = get_result(result)\n",
    "print ('Predicted Alphabet is: {}'.format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Predicting the Alphabet from the Input Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of code is receives the input image from the anvil website and returns the predicted alphabet back to the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def model_run(path):\n",
    "    with anvil.media.TempFile(path) as filename:\n",
    "        test_image = image.load_img(filename, target_size = (32,32))\n",
    "        test_image = image.img_to_array(test_image)\n",
    "        test_image = np.expand_dims(test_image, axis = 0)\n",
    "        result = model.predict(test_image)\n",
    "        result = get_result(result)\n",
    "        return ('Predicted Alphabet is: {}'.format(result))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
